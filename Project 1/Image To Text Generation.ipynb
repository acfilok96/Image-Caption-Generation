{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtV7d8gaTxFP"
   },
   "outputs": [],
   "source": [
    "# How to use zip or tar or rar or tar.gz file in colab\n",
    "\n",
    "# https://colab.research.google.com/github/sudo-ken/compress-decompress-in-Google-Drive/blob/master/Unrar_Unzip_Rar_Zip_in_GDrive.ipynb#scrollTo=YfSkw7IFH2pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5-Cdgq4wcNP"
   },
   "outputs": [],
   "source": [
    "# official webpage :- https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBBeX-shgEoE"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HB8fcMAoCzyS"
   },
   "outputs": [],
   "source": [
    "!unzip Flickr8k_Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_0hmPuxIR13"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3Uxh2kSC3hI"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWhHN_PYC5SF"
   },
   "outputs": [],
   "source": [
    "!unzip Flickr8k_text.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scLdKuAqC7Qj"
   },
   "outputs": [],
   "source": [
    "image_path = '/content/Flicker8k_Dataset'\n",
    "text_path = '/content/Flickr8k.token.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMmmYcb-y-jX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FT_8rQd1C9ZI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "with tf.device(device_name):\n",
    "  # image data set \n",
    "  image_id_in_photo=[]\n",
    "  mapping_image = dict()\n",
    "  import os\n",
    "  for name in os.listdir(image_path):\n",
    "    photo = image_path+'/'+name\n",
    "    name_id = name.split('.')[0]\n",
    "    image_id_in_photo.append(name_id)\n",
    "    if name_id not in mapping_image:\n",
    "      mapping_image[name_id] = list()\n",
    "    mapping_image[name_id].append(photo)\n",
    "  \n",
    "  # text data set\n",
    "  text = open(text_path, 'r').read()\n",
    "  mapping_text = dict()\n",
    "  image_id_in_text=[]\n",
    "  for line in text.split('\\n'):\n",
    "    tokens = line.split()\n",
    "    if len(line) < 2:\n",
    "      continue\n",
    "    image_id, image_desc = tokens[0], tokens[1:]\n",
    "    image_id = image_id.split('.')[0]\n",
    "    image_desc = ' '.join(image_desc)\n",
    "    image_id_in_text.append(image_id)\n",
    "    if image_id not in mapping_text:\n",
    "      mapping_text[image_id] = list()\n",
    "    mapping_text[image_id].append(image_desc)\n",
    "\n",
    "  # check number of data in image_set and text_set\n",
    "  print('image_id_in_photo --> ',len(image_id_in_photo))\n",
    "  print('image_id_in_text --> ',len(image_id_in_text),'\\n')\n",
    "\n",
    "  k=''\n",
    "  for i in image_id_in_text:\n",
    "    if i not in image_id_in_photo:\n",
    "      k=str(i)\n",
    "      print(k)\n",
    "  temp=[]\n",
    "  for i in image_id_in_text:\n",
    "    if str(i) != k:\n",
    "      temp.append(i)\n",
    "  image_id_in_text=temp\n",
    "  mapping_text.pop(k)\n",
    "  \n",
    "  print('image_id_in_photo --> ',len(image_id_in_photo))\n",
    "  print('image_id_in_text --> ',len(image_id_in_text),'\\n')\n",
    "\n",
    "  # set text and photo serially in another folder\n",
    "  image_set = []\n",
    "  text_set = []\n",
    "  for i in image_id_in_photo:\n",
    "    image_set.append(mapping_image[i])\n",
    "    text_set.append(mapping_text[i])\n",
    "  print('image_set --> ',len(image_set))\n",
    "  print('text_set --> ',len(text_set),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tH3_-ssJBXzU"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "  # part 1\n",
    "  from keras.applications.vgg16 import VGG16\n",
    "  from keras.preprocessing.image import load_img\n",
    "  from keras.preprocessing.image import img_to_array\n",
    "  from keras.applications.vgg16 import preprocess_input\n",
    "  from keras.models import Model\n",
    "\n",
    "  model = VGG16()\n",
    "  model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "  #print('\\n\\n\\n',model.summary())\n",
    "\n",
    "  img_1 = []\n",
    "  txt_1 = []\n",
    "  mark = 0\n",
    "  for i in range(len(image_set)):\n",
    "    image = load_img(image_set[i][0], target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    feature = model.predict(image, verbose=0)\n",
    "\n",
    "    mark +=1\n",
    "    if mark == 10:\n",
    "      break\n",
    "    \n",
    "    import string\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    p = text_set[i]\n",
    "    for j in range(len(p)):\n",
    "      desc = p[j]\n",
    "      desc = desc.split()\n",
    "      desc = [word.lower() for word in desc]\n",
    "      desc = [w.translate(table) for w in desc]\n",
    "      desc = [word for word in desc if len(word)>1]\n",
    "      desc = [word for word in desc if word.isalpha()]\n",
    "      desc = 'startseq ' + ' '.join(desc) + ' endseq'\n",
    "      img_1.append(feature)\n",
    "      txt_1.append(desc)\n",
    "\n",
    "  # part 2\n",
    "  print('img_1 --> ',len(img_1))\n",
    "  print('txt_1 --> ',len(txt_1))\n",
    "  print('DONE!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LthJTEGaOID1"
   },
   "outputs": [],
   "source": [
    "# for checking weather the data sets are good fitted or not \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "with tf.device(device_name):\n",
    "  a = random.randint(0,len(image_set)-1)\n",
    "  image = tf.keras.preprocessing.image.load_img(str(image_set[a][0]),target_size=(224, 224))\n",
    "  text = text_set[a]\n",
    "  print(text)\n",
    "  plt.imshow(image)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1-3UJ3jDXsg"
   },
   "outputs": [],
   "source": [
    "#img_1 = img_1[:5*100]\n",
    "#txt_1 = txt_1[:5*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yW7xgdO85jKB"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "  # part 3\n",
    "  x_1_train = []\n",
    "  x_2_train = []\n",
    "  y_train = []\n",
    "  \n",
    "  import tensorflow\n",
    "  from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "  from keras.preprocessing.sequence import pad_sequences\n",
    "  from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(txt_1)\n",
    "  text_1 = tokenizer.texts_to_sequences(txt_1)\n",
    "\n",
    "  maxlen = max([max(i) for i in text_1])\n",
    "\n",
    "  for j in range(len(text_1)):\n",
    "    seq = text_1[j]\n",
    "    ph = img_1[j]\n",
    "    for i in range(1,len(seq)):\n",
    "      in_seq , out_seq = seq[:i], seq[i]\n",
    "      in_seq = pad_sequences([in_seq], maxlen=maxlen+1)[0]\n",
    "      out_seq = to_categorical([out_seq], num_classes=maxlen+1)[0]\n",
    "      x_1_train.append(ph)\n",
    "      x_2_train.append(in_seq)\n",
    "      y_train.append(out_seq)\n",
    "\n",
    "  # part 4\n",
    "  print('x_1_train --> ',len(x_1_train))\n",
    "  print('x_2_train --> ',len(x_2_train))\n",
    "  print('y_train --> ',len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 1025)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1025, 256)    262400      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1025, 256)    0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 1025, 256)    525312      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4096)         0           ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 1025, 256)    0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          1048832     ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 256)          525312      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['dense_3[0][0]',                \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1025)         263425      ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,691,073\n",
      "Trainable params: 2,691,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# part 5\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import add\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def model_function(image_size = 4096, text_maxlen=1024):\n",
    "    inputs1 = Input(shape=(image_size,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    inputs2 = Input(shape=(text_maxlen+1,))\n",
    "    se1 = Embedding(text_maxlen+1, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256,return_sequences=True)(se2)\n",
    "    se4 = Dropout(0.5)(se3)\n",
    "    se5 = LSTM(256)(se4)\n",
    "\n",
    "    decoder1 = add([fe2, se5])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(text_maxlen+1, activation='softmax')(decoder2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = model_function(image_size = 4096, text_maxlen=1024)\n",
    "print(model.summary())\n",
    "#   plot_model(model, to_file='model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQVyb6mWx4Xi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_1_train = np.array(x_1_train)\n",
    "x_2_train = np.array(x_2_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(x_1_train.shape)\n",
    "print(x_2_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wARcKpT0SP1"
   },
   "outputs": [],
   "source": [
    "x_1_train = x_1_train.reshape((x_1_train.shape[0],x_1_train.shape[2]))\n",
    "print(x_1_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc5Hy8CnPMhj"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "  model.fit([x_1_train, x_2_train], y_train, epochs = 10, shuffle = True, batch_size = 256, validation_data =([x_1_train, x_2_train], y_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0LSd39LxofS"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/model_image_to_text.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaSngkoZ-7qC"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/model_image_to_text_copy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ66bo8OsbCB"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with tf.device(device_name):\n",
    "  filename = '/content/drive/My Drive/DATA_SET/CNN/image_1976.jpg'\n",
    "  import matplotlib.pyplot as plt\n",
    "  filename = load_img(filename,target_size=(224, 224))\n",
    "  plt.imshow(filename)\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VafNs33nsgu"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "  from numpy import argmax\n",
    "  from keras.preprocessing.sequence import pad_sequences\n",
    "  from keras.applications.vgg16 import VGG16\n",
    "  from keras.preprocessing.image import load_img\n",
    "  from keras.preprocessing.image import img_to_array\n",
    "  from keras.applications.vgg16 import preprocess_input\n",
    "  from keras.models import Model\n",
    "  from keras.models import load_model\n",
    "\n",
    "  model_2 = load_model('/content/drive/My Drive/model_image_to_text.h5')\n",
    "\n",
    "  #text\n",
    "  #filename = '/content/drive/My Drive/DATA_SET/CNN/image_1976.jpg'\n",
    "  filename = image_set[5][0]\n",
    "\n",
    "  model_1 = VGG16()\n",
    "  model_1 = Model(inputs=model_1.inputs, outputs=model_1.layers[-2].output)\n",
    "  image = load_img(filename, target_size=(224, 224))\n",
    "  image = img_to_array(image)\n",
    "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "  image = preprocess_input(image)\n",
    "  feature = model_1.predict(image, verbose=0)\n",
    "\t\n",
    "  in_text = 'startseq'\n",
    "  for i in range(maxlen+1):\n",
    "    sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    sequence = pad_sequences([sequence], maxlen=maxlen+1)\n",
    "    yhat = model_2.predict([feature,sequence], verbose=0)\n",
    "    yhat = argmax(yhat)\n",
    "    word = ''\n",
    "    for word_1, index in tokenizer.word_index.items():\n",
    "      if index == yhat:\n",
    "        word = word_1\n",
    "    if word is None:\n",
    "      break\n",
    "    in_text += ' ' + word\n",
    "    if word == 'endseq':\n",
    "      break\n",
    "  in_text = in_text.split()\n",
    "  in_text.pop(0)\n",
    "  in_text.pop(len(in_text)-1)\n",
    "  in_text = ' '.join(in_text)\n",
    "  print(in_text)\n",
    "\n",
    "  #image\n",
    "  import matplotlib.pyplot as plt\n",
    "  filename = load_img(filename,target_size=(224, 224))\n",
    "  plt.imshow(filename)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4jvL0SAAFGY"
   },
   "outputs": [],
   "source": [
    "filename = image_set[5][0]\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mh8iJ18gGsla"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
